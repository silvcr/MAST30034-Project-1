{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a1eb52f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/binhducvu/jupyterenv/lib/python3.8/site-packages/geopandas/_compat.py:106: UserWarning: The Shapely GEOS version (3.8.0-CAPI-1.13.1 ) is incompatible with the GEOS version PyGEOS was compiled with (3.9.1-CAPI-1.14.2). Conversions between both will be slow.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#getting all the necessary geojson files\n",
    "\n",
    "import geopandas as gpd\n",
    "#converting the NTA and taxi zones data into geojson files\n",
    "directory = \"../raw_data_lite/\"\n",
    "taxi_zones_shp = gpd.read_file(f\"{directory}taxi_zones.shp\")\n",
    "taxi_zones_shp.to_file(f\"{directory}taxi_zones.geojson\", drivers = 'GeoJSON')\n",
    "\n",
    "nta_shp = gpd.read_file(f\"{directory}nynta_21b/nynta.shp\")\n",
    "nta_shp.to_file(f\"{directory}nta.geojson\", drivers = 'GeoJSON')\n",
    "#reading the files in as dataframes\n",
    "taxi_zones = gpd.read_file(f\"{directory}taxi_zones.geojson\")\n",
    "nta = gpd.read_file(f\"{directory}nta.geojson\")\n",
    "boroughs = gpd.read_file(f\"{directory}Borough Boundaries.geojson\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8390108d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21/08/09 02:58:34 WARN Utils: Your hostname, LAPTOP-D5HGLKLK resolves to a loopback address: 127.0.1.1; using 172.23.50.214 instead (on interface eth0)\n",
      "21/08/09 02:58:34 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "21/08/09 02:58:36 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "# Importing and starting a spark session\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkContext\n",
    "#Supress warnings\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "sc = SparkContext.getOrCreate()\n",
    "sc.setLogLevel('WARN')\n",
    "\n",
    "spark.conf.set('spark.sql.execution.arrow.pyspark.enabled', True)\n",
    "#Make the spark files present well\n",
    "spark.conf.set('spark.sql.repl.eagerEval.enabled', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eccc24fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 0:>                                                          (0 + 1) / 1]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# reference from Akira Wang's Github\n",
    "#forming a schema for the dataframes\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "#setting datatypes for each individual column\n",
    "ints = ('VendorID', 'passenger_count', 'RateCodeID', 'RatecodeID','payment_type', 'PULocationID', 'DOLocationID')\n",
    "doubles = ('trip_distance', 'fare_amount', 'extra', 'mta_tax', 'tip_amount', 'tolls_amount', 'improvement_surcharge', 'total_amount'\n",
    "          , 'congestion_surcharge')\n",
    "strings = ('store_and_fwd_flag',)\n",
    "dtimes = ('tpep_pickup_datetime', 'tpep_dropoff_datetime')\n",
    "\n",
    "\n",
    "dtypes = {column: IntegerType() for column in ints}\n",
    "dtypes.update({column: DoubleType() for column in doubles})\n",
    "dtypes.update({column: StringType() for column in strings})\n",
    "dtypes.update({column: TimestampType() for column in dtimes})\n",
    "\n",
    "taxi_dir = \"../raw_data/yellow_tripdata_20\"\n",
    "#Using a dataset to form the schema\n",
    "sdf = spark.read.csv(f\"{taxi_dir}18-01.csv\", header = True)\n",
    "\n",
    "schema = StructType()\n",
    "for column in sdf.columns:\n",
    "    schema.add(column, # column name\n",
    "               dtypes[column], # data type\n",
    "               True # is nullable?\n",
    "              )\n",
    "#importing the taxi datasets in dictionaries with schemas\n",
    "\n",
    "\n",
    "taxi18 = {str(i).zfill(2): spark.read.csv(f\"{taxi_dir}18-{str(i).zfill(2)}.csv\",\n",
    "                                                     header = True, schema = schema) for i in range(1, 13)}\n",
    "taxi19 = {str(i).zfill(2): spark.read.csv(f\"{taxi_dir}19-{str(i).zfill(2)}.csv\",\n",
    "                                                     header = True, schema = schema) for i in range(1, 13)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "485d76ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#merging the taxi zones and the NTA into a new dataframe\n",
    "merged_zones = gpd.sjoin(taxi_zones, nta, how = 'right')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c91b8bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create and form a dictionary to convert the Taxi Zone LocationID into NTA Codes\n",
    "# based on the merged geojson file.\n",
    "taxi_zone_to_nta = {}\n",
    "\n",
    "for index, row in merged_zones.iterrows():\n",
    "    taxi_zone_to_nta[row['OBJECTID']] = row['NTACode']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6d82662d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *\n",
    "#summarising all the 2018 data into 1 dataframe\n",
    "full_2018 = taxi18['01']\n",
    "for i in range(2, 13):\n",
    "    full_2018 = full_2018.union(taxi18[str(i).zfill(2)])\n",
    "\n",
    "#filter out all payment types not credit card\n",
    "full_2018 = full_2018.filter(full_2018.payment_type == 1)\n",
    "\n",
    "#filter out all payment types that involve Newark Airport\n",
    "full_2018 = full_2018.filter(full_2018.PULocationID != 1)\n",
    "full_2018 = full_2018.filter(full_2018.DOLocationID != 1)\n",
    "\n",
    "#filter out all negative trip distances\n",
    "full_2018 = full_2018.filter(full_2018.trip_distance > 0)\n",
    "\n",
    "#remove all ratecodes not contained within New York City\n",
    "full_2018 = full_2018.filter((full_2018.RatecodeID != 3) & (full_2018.RatecodeID != 4) & \n",
    "                             (full_2018.RatecodeID != 99))\n",
    "\n",
    "#remove all LocationIDs that are unexplained (posed to be out of state)\n",
    "full_2018 = full_2018.filter((full_2018.PULocationID != 264) & (full_2018.PULocationID != 265)\n",
    "                            & (full_2018.DOLocationID != 264) & (full_2018.DOLocationID != 265))\n",
    "\n",
    "#remove all trips not in 2018\n",
    "full_2018.filter(year(full_2018.tpep_pickup_datetime) != 2018).limit(5)\n",
    "\n",
    "#creating a new column corresponding to trip duration in minutes\n",
    "full_2018 = full_2018.withColumn(\"trip_duration\", \n",
    "                                (full_2018.tpep_pickup_datetime.cast('long') - \n",
    "                                full_2018.tpep_dropoff_datetime.cast('long'))/60)\n",
    "\n",
    "#filter out all negative trip durations\n",
    "full_2018 = full_2018.filter(full_2018.trip_duration > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3e3f17f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "full_2018.write.format('parquet').save('../preprocessed_data/preprocessed_2018_taxi_data.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "868f4ab1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
